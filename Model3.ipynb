{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "# to ignore the warnings\n",
    "from warnings import filterwarnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9510 entries, 0 to 9509\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   home_team       9510 non-null   object \n",
      " 1   visitor_team    9510 non-null   object \n",
      " 2   visitor_points  9510 non-null   float64\n",
      " 3   visitor_fgm     9510 non-null   float64\n",
      " 4   home_points     9510 non-null   float64\n",
      " 5   home_fgm        9510 non-null   float64\n",
      " 6   visitor_ORtg    9510 non-null   float64\n",
      " 7   home_ORtg       9510 non-null   float64\n",
      " 8   visitor_DRtg    9510 non-null   float64\n",
      " 9   home_DRtg       9510 non-null   float64\n",
      " 10  total_points    9510 non-null   float64\n",
      "dtypes: float64(9), object(2)\n",
      "memory usage: 817.4+ KB\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.read_csv('./data/totalPredict_ML3.csv')\n",
    "total_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "home_team         0\n",
       "visitor_team      0\n",
       "visitor_points    0\n",
       "visitor_fgm       0\n",
       "home_points       0\n",
       "home_fgm          0\n",
       "visitor_ORtg      0\n",
       "home_ORtg         0\n",
       "visitor_DRtg      0\n",
       "home_DRtg         0\n",
       "total_points      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9510, 11)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner_df = pd.read_csv('./data/winPredict_ML3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9510 entries, 0 to 9509\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   home_team       9510 non-null   object \n",
      " 1   visitor_team    9510 non-null   object \n",
      " 2   visitor_points  9510 non-null   float64\n",
      " 3   home_points     9510 non-null   float64\n",
      " 4   visitor_ORtg    9510 non-null   float64\n",
      " 5   home_ORtg       9510 non-null   float64\n",
      " 6   visitor_DRtg    9510 non-null   float64\n",
      " 7   home_DRtg       9510 non-null   float64\n",
      " 8   visitor_efg%    9509 non-null   float64\n",
      " 9   home_efg%       9509 non-null   float64\n",
      " 10  visitor_ts%     9510 non-null   float64\n",
      " 11  home_ts%        9510 non-null   float64\n",
      " 12  home_win        9510 non-null   int64  \n",
      "dtypes: float64(10), int64(1), object(2)\n",
      "memory usage: 966.0+ KB\n"
     ]
    }
   ],
   "source": [
    "winner_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9510, 13)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# winner_df['is_home'] = (winner_df['home_team'] == winner_df['home_team']).astype(int)\n",
    "# winner_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7552\\1442891978.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  new_total_df = encoded_total_df.replace({True: 1, False: 0})\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_7552\\1442891978.py:7: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  new_winner_df = encoded_winner_df.replace({True: 1, False: 0})\n"
     ]
    }
   ],
   "source": [
    "# Apply one-hot encoding to categorical columns\n",
    "encoded_total_df = pd.get_dummies(total_df, columns=['visitor_team', 'home_team'])\n",
    "encoded_winner_df = pd.get_dummies(winner_df, columns=['visitor_team', 'home_team'])\n",
    "\n",
    "# Covert booleans to integers\n",
    "new_total_df = encoded_total_df.replace({True: 1, False: 0})\n",
    "new_winner_df = encoded_winner_df.replace({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_winner_df = new_winner_df.dropna()\n",
    "new_total_df = new_total_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoded_total_df: (9510, 69)\n",
      "Shape of encoded_winner_df: (9509, 71)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of encoded_total_df: {new_total_df.shape}\")\n",
    "print(f\"Shape of encoded_winner_df: {new_winner_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Create feature values\n",
    "X_total = new_total_df.drop(columns=['home_points', 'visitor_points', 'total_points'])\n",
    "X_winner = new_winner_df.drop(columns=['home_points', 'visitor_points', 'home_win'])\n",
    "\n",
    "# Create target values\n",
    "y_total = new_total_df['total_points']\n",
    "y_winner = new_winner_df['home_win']\n",
    "\n",
    "# Split training data\n",
    "X_total_train, X_total_test, y_total_train, y_total_test = train_test_split(\n",
    "    X_total, \n",
    "    y_total, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_winner_train, X_winner_test, y_winner_train, y_winner_test = train_test_split(\n",
    "    X_winner, \n",
    "    y_winner, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Initiate Scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Train the classification model (winner predictions)\n",
    "clf_model = DecisionTreeClassifier().fit(X_winner_train, y_winner_train)\n",
    "\n",
    "# Scale training data\n",
    "X_total_train.replace([np.inf, -np.inf], np.nan, inplace=True) # X_total_train contained infinite values\n",
    "X_total_train.fillna(X_total_train.mean(), inplace=True) # Fill with column mean\n",
    "\n",
    "X_total_train_scaled = scaler.fit_transform(X_total_train)\n",
    "\n",
    "# Train regression model (total prediction)\n",
    "linear_model = LinearRegression().fit(X_total_train_scaled, y_total_train)\n",
    "\n",
    "# Scale the test data\n",
    "X_total_test_scaled = scaler.transform(X_total_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[916  10]\n",
      " [  5 971]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       926\n",
      "           1       0.99      0.99      0.99       976\n",
      "\n",
      "    accuracy                           0.99      1902\n",
      "   macro avg       0.99      0.99      0.99      1902\n",
      "weighted avg       0.99      0.99      0.99      1902\n",
      "\n",
      "Accuracy: 0.9921135646687698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report # type: ignore\n",
    "\n",
    "# Evaluate the classification model\n",
    "y_winner_pred = clf_model.predict(X_winner_test)\n",
    "print(confusion_matrix(y_winner_test, y_winner_pred))\n",
    "print(classification_report(y_winner_test, y_winner_pred))\n",
    "print(\"Accuracy:\", accuracy_score(y_winner_test, y_winner_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 75.12772573836824\n",
      "R2 Score: 0.8366578889853996\n"
     ]
    }
   ],
   "source": [
    "y_total_pred = linear_model.predict(X_total_test_scaled)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"MSE:\", mean_squared_error(y_total_test, y_total_pred))\n",
    "print(\"R2 Score:\", r2_score(y_total_test, y_total_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_score\n",
    "# scores = cross_val_score(clf_model, X_winner, y_winner, cv=5)\n",
    "# print(\"Cross-Validation Scores:\", scores)\n",
    "# print(\"Mean CV Accuracy:\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# param_grid = {\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "# grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
    "# grid_search.fit(X_winner_train, y_winner_train)\n",
    "# print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Game Prediction ---\n",
      "Predicted Winner: Phoenix Suns\n"
     ]
    }
   ],
   "source": [
    "# Inputs for the home and visitor teams\n",
    "visitor_team = input(\"Enter Away Team: \")\n",
    "home_team = input(\"Enter Home Team: \")\n",
    "\n",
    "# Create input data with correct features for the models\n",
    "input_data_winner = {col: 0 for col in X_winner.columns}\n",
    "input_data_total = {col: 0 for col in X_total.columns}\n",
    "\n",
    "# Populate the features based on the provided teams\n",
    "if f'home_team_{home_team}' in input_data_winner:\n",
    "    input_data_winner[f'home_team_{home_team}'] = 1\n",
    "if f'visitor_team_{visitor_team}' in input_data_winner:\n",
    "    input_data_winner[f'visitor_team_{visitor_team}'] = 1\n",
    "    \n",
    "    \n",
    "if f'home_team_{home_team}' in input_data_total:\n",
    "    input_data_winner[f'home_team_{home_team}'] = 1    \n",
    "if f'visitor_team_{visitor_team}' in input_data_total:\n",
    "    input_data_winner[f'visitor_team_{visitor_team}'] = 1\n",
    "    \n",
    "# Convert dictionaries to DataFrames\n",
    "input_df_winner = pd.DataFrame([input_data_winner])\n",
    "input_df_total = pd.DataFrame([input_data_total])\n",
    "\n",
    "# Scale the input data for the total points\n",
    "input_df_total_scaled = scaler.transform(input_df_total)\n",
    "\n",
    "# Predict the winner using the classification model\n",
    "predicted_winner = clf_model.predict(input_df_winner)[0]\n",
    "predict_total_points = linear_model.predict(input_df_total_scaled)[0]\n",
    "\n",
    "# Map the winner prediction to the team name\n",
    "winner = home_team if predicted_winner == 1 else visitor_team\n",
    "\n",
    "print(\"\\n--- Game Prediction ---\")\n",
    "print(f\"Predicted Winner: {winner}\")\n",
    "# print(f\"Predicted Total Points: {round(predict_total_points, 0)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Model 1 ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "X = model_df.drop(columns=['winner','home_points', 'visitor_points', 'total_points'])\n",
    "X_df = pd.DataFrame(X, columns=model_df.drop(columns=['winner', 'home_points', 'visitor_points', 'total_points']).columns)\n",
    "\n",
    "# Create both target variables\n",
    "y_winner = model_df['winner']\n",
    "y_total_points = model_df['total_points']\n",
    "\n",
    "# Splitting data\n",
    "X_train, X_test, y_train_winner, y_test_winner = train_test_split(X_df, y_winner, test_size=0.2, random_state=42)\n",
    "_, _, y_train_points, y_test_points = train_test_split(X_df, y_total_points, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train the classification model (winner prediction)\n",
    "clf_model = DecisionTreeClassifier().fit(X_train, y_train_winner)\n",
    "\n",
    "# Train regression model (total_points)\n",
    "linear_model = LinearRegression().fit(X_train_scaled, y_train_points)\n",
    "\n",
    "# Scale the test data\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
